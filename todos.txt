prepare_train:
    -> saving weights (last or best)✅
    -> specifying train method (how train files are being passed - randomly/ one after another, etc.)✅

prepare_dataset module:
    -> read dataset from file/files/train_test_files
    -> obtaining multivariate timeseries
    -> 

weight_optimization:
    -> other methods of optimization
    -> optional aggregation weights optimization✅
    -> make passing window transformation function optional

util/data_prep:
    -> different rescaling limits✅
    -> read from arffs (using read_file module)✅
    -> add rescaling to data read from arff✅
    -> add support for rescaling limits for arff files

preprocessing/read_file:
    -> read dimensions from different files OR 
    -> from one file✅
    -> specify class type✅

testing:
    -> modify code to perform testing on arff data✅
    -> calculate errors

main:
    -> saving results✅
    -> universal file naming✅
    -> passing dimensions of timeseries as a parameter✅

-> early stopping
-> get rid of nans
-> get this module ready to perform our previous calculations

input file with parameters:
    -> dataset tr/te paths
        -> method of passing files (specific files, random, crossval) (tr and te)
        -> class of training files
    -> classifier type
        -> specific parameters to classifier
    -> output path

script for generating input files

util/results_aggregation:
    -> perform results aggregation based on resulting .json files